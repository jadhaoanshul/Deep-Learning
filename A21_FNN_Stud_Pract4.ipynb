{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jadhaoanshul/Deep-Learning/blob/main/A21_FNN_Stud_Pract4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DL Lab4\n",
        "### Name : Anshul Jadhao <br> Batch and Roll No. : A2 & 21"
      ],
      "metadata": {
        "id": "RHfYETzuA3D8"
      },
      "id": "RHfYETzuA3D8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8d33d42-506c-46cd-87d1-296dd5bba33b",
      "metadata": {
        "id": "c8d33d42-506c-46cd-87d1-296dd5bba33b"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiirrfDSlLBk",
        "outputId": "c5e971ae-108e-4b9f-df66-94bfa8cce997"
      },
      "id": "OiirrfDSlLBk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2df8e227-8f7f-4d7f-9c2e-e87885618ce5",
      "metadata": {
        "id": "2df8e227-8f7f-4d7f-9c2e-e87885618ce5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Practical 4\n",
        "Create a neural network from scratch for a multiclass\n",
        "classification task with the following architecture:\n",
        "\n",
        "\n",
        "Input\n",
        "layer: 4 neurons\n",
        "First\n",
        "hidden layer: 3 neurons\n",
        "Second\n",
        "hidden layer: 4 neurons\n",
        "Output\n",
        "layer: 3 neurons\n",
        "\n",
        "\n",
        "\n",
        "Generate a random dataset for a 3-class classification\n",
        "problem. Apply the designed neural network on the generated dataset using the\n",
        "ReLU activation function in the hidden layers and the softmax activation\n",
        "function in the output layer for multiclass classification. Use binary\n",
        "cross-entropy as the loss function for training. Additionally, implement the\n",
        "all optimizer as part of the training process. Train\n",
        "the neural network using both optimizers and evaluate their performance on the\n",
        "dataset using performance metrics accuracy."
      ],
      "metadata": {
        "id": "q6UyGL6-sY0T"
      },
      "id": "q6UyGL6-sY0T"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "tHAMYkdlA90t"
      },
      "id": "tHAMYkdlA90t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Generate a Random Dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=4, n_classes=3,\n",
        "                           n_informative=3, n_redundant=1, random_state=42)\n",
        "\n",
        "print(\"Generated Dataset:\")\n",
        "print(\"Features:\", X[:100])\n",
        "print(\"Labels:\", y[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_78Vc9tpU9p",
        "outputId": "78fa0ee4-bc08-453e-ba76-29e0c7bd3f41"
      },
      "id": "2_78Vc9tpU9p",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Dataset:\n",
            "Features: [[-7.63576538e-01 -1.37636780e+00 -1.32921216e+00 -8.11225933e-01]\n",
            " [ 7.98775852e-01  1.47910302e+00 -1.23529644e-01 -1.82966415e+00]\n",
            " [ 2.51710984e-01 -1.18311957e+00  1.43640980e+00 -1.22878966e+00]\n",
            " [-6.28048368e-01 -1.59609361e+00 -4.00481649e-01 -3.44888165e-01]\n",
            " [-1.79159244e-01 -1.20240680e+00  8.72088789e-01  1.85406163e-01]\n",
            " [ 7.25190407e-01  9.57999500e-01  2.77721980e-01 -1.73024099e+00]\n",
            " [ 8.54206543e-02 -1.27342358e+00  1.43129091e+00 -4.63386321e-01]\n",
            " [-6.65310449e-01 -1.86756351e+00  2.98640433e-02  1.03861546e-01]\n",
            " [ 6.31590041e-01  1.56118235e+00 -5.40054565e-01 -1.45942625e+00]\n",
            " [-1.79709358e-01  7.05105160e-01 -1.58896826e-01  2.17324320e+00]\n",
            " [-3.67291461e-01 -2.13909705e-01 -1.18315245e+00 -4.73256644e-01]\n",
            " [-4.65540563e-01 -5.02640909e-01  8.73697402e-02  1.82215198e+00]\n",
            " [ 9.91744255e-01  1.60315473e+00  1.82397318e+00  8.57775705e-01]\n",
            " [-7.02461689e-01 -5.70732438e-01 -1.11007435e+00  8.67396268e-01]\n",
            " [ 5.40165050e-01  8.31787270e-01  1.26270350e+00  8.73844404e-01]\n",
            " [-3.53378718e-02 -3.95917581e-01  5.24282985e-01  3.56777053e-01]\n",
            " [ 1.63877134e-01 -4.35091937e-01  1.23916463e+00  4.32447817e-01]\n",
            " [-4.42740144e-01 -5.06782681e-01  2.37259844e-01  1.95549875e+00]\n",
            " [-9.98523945e-01 -2.53930831e+00 -1.00036777e-01  4.25804790e-01]\n",
            " [ 9.81274245e-01  1.79167983e+00 -3.53805679e-02 -2.08706406e+00]\n",
            " [-8.12115991e-01 -2.77017120e+00  1.03873251e+00  9.59191033e-01]\n",
            " [ 1.08682940e+00  2.55861294e+00  1.50122789e+00  1.65710265e+00]\n",
            " [-1.34715158e-01 -4.19041984e-01  1.26310520e+00  2.22801447e+00]\n",
            " [-3.06056691e-01 -1.24645999e+00  9.27720376e-01  9.28279769e-01]\n",
            " [ 1.47257020e-01 -1.26967853e+00  1.56502528e+00 -5.68287584e-01]\n",
            " [-8.65799068e-02 -5.76346992e-01  1.31172503e+00  1.72085076e+00]\n",
            " [-8.62224434e-01 -1.46197917e-01 -1.58002372e+00  1.79103427e+00]\n",
            " [ 4.71437686e-01  1.06854546e+00 -5.73731899e-01 -1.59610053e+00]\n",
            " [-4.52499547e-01  5.73146261e-01 -1.13035821e+00  1.70734848e+00]\n",
            " [ 4.53324611e-01 -1.03217141e+00  1.54176061e+00 -1.89222477e+00]\n",
            " [ 1.10778266e+00  7.82670844e-01  2.78549661e+00  2.79563558e-01]\n",
            " [-4.81437646e-01  6.75457258e-02 -2.83793078e+00 -2.26024891e+00]\n",
            " [-4.45608163e-01 -1.26282652e+00 -3.96290749e-01 -7.12989068e-01]\n",
            " [-2.90274304e-01  7.19022061e-01 -9.11035594e-01  1.46806611e+00]\n",
            " [ 1.20921859e-01 -1.24739011e+00  1.51898532e+00 -4.55365687e-01]\n",
            " [-7.74730009e-01 -1.81804566e+00 -5.92458018e-01 -2.99354038e-01]\n",
            " [-4.51808867e-01 -1.85798388e+00  1.41128608e+00  1.41011841e+00]\n",
            " [-6.76256343e-01 -2.59313155e-01 -1.34020656e+00  9.27910584e-01]\n",
            " [-3.48065299e-01 -1.55406341e+00  1.33747941e+00  1.29369388e+00]\n",
            " [ 9.94682410e-01  2.65093575e+00  1.00609132e+00  1.47277446e+00]\n",
            " [-6.72848530e-01  2.06871930e-01 -2.27215930e+00  1.54706526e-01]\n",
            " [-1.29344220e+00 -2.90932003e+00 -7.09647415e-01  2.64412068e-01]\n",
            " [-1.03040743e-01 -1.64632440e-01  9.23599916e-01  1.94236444e+00]\n",
            " [-7.32973782e-01  8.22458706e-01 -2.47547787e+00  1.37713128e+00]\n",
            " [-3.31132855e-01 -6.69031039e-02 -1.58685060e-02  1.74246175e+00]\n",
            " [-3.13855731e-01 -4.77298373e-01 -1.39014008e+00 -1.69135896e+00]\n",
            " [ 5.07439579e-02  2.56661445e-01  4.98600630e-01  1.13574149e+00]\n",
            " [ 3.98898942e-01  1.25044859e+00  9.00966392e-01  1.87618872e+00]\n",
            " [-1.05733613e+00 -1.57710967e+00 -2.23810538e+00 -1.18168029e+00]\n",
            " [-6.90231521e-02 -9.15692041e-01  5.86748429e-01 -3.87988315e-01]\n",
            " [-1.71438359e-01 -5.85285327e-01  4.16048564e-01  5.59900707e-01]\n",
            " [-1.10386738e-01  4.01415548e-01 -1.13621746e+00 -6.21145838e-01]\n",
            " [-1.20910295e+00 -2.35740484e+00 -1.47989478e+00 -5.06685594e-01]\n",
            " [-3.98758818e-01 -1.77322258e-01 -4.18535784e-01  1.17481863e+00]\n",
            " [ 1.05093640e-01  2.17523614e+00 -1.10261342e+00  1.79114274e+00]\n",
            " [-7.86172385e-01 -6.72531882e-01 -1.42096514e+00  5.77007090e-01]\n",
            " [ 8.77588354e-02 -1.26713227e+00  1.49101261e+00 -3.55325597e-01]\n",
            " [-6.27513469e-01 -2.92383895e+00  1.90690862e+00  1.16639509e+00]\n",
            " [-9.23348506e-01 -4.65996041e+00  2.48383734e+00  4.05282522e-01]\n",
            " [-6.30568226e-01 -1.08529317e+00 -1.38488094e+00 -1.08914631e+00]\n",
            " [-1.70854461e-03  5.81857976e-02  4.93968690e-01  1.02744739e+00]\n",
            " [-6.56645128e-01 -2.57362455e+00  1.25303789e+00  8.52271852e-01]\n",
            " [-2.17936308e-02 -5.88326673e-01  1.65505235e+00  1.94890239e+00]\n",
            " [ 7.71398383e-01  1.39120921e+00 -2.03076777e-01 -1.99489034e+00]\n",
            " [-3.02880386e-01 -1.30026802e+00  2.40002583e-01 -4.51676897e-01]\n",
            " [ 9.08575926e-01  6.20195242e-01  2.51228101e+00  6.00023166e-01]\n",
            " [-1.52287024e-02  2.02062195e-01  9.47757109e-02  6.69502618e-01]\n",
            " [ 4.31394823e-02 -1.35017375e+00  1.61285062e+00 -4.46064819e-02]\n",
            " [ 1.01605893e+00  2.29346174e+00  1.30042733e+00  1.16194829e+00]\n",
            " [ 1.12135728e-01 -1.36286318e+00  1.72478120e+00 -2.63734053e-01]\n",
            " [ 1.54532690e-01  1.22099906e-01 -6.65593945e-01 -1.85504173e+00]\n",
            " [ 2.37517121e-01 -1.42204839e+00  1.93853544e+00 -7.16234552e-01]\n",
            " [-9.13608445e-01 -1.44488382e+00 -1.86799745e+00 -1.06742269e+00]\n",
            " [ 1.54607521e-01 -1.18864942e+00  1.52964623e+00 -5.10978750e-01]\n",
            " [-4.24804169e-01 -1.28176138e+00 -2.92434992e-01 -6.81954792e-01]\n",
            " [-6.17672133e-01 -9.48114240e-01 -1.34877009e+00 -8.19848624e-01]\n",
            " [-2.60178955e-01 -3.12301294e-01  2.72861412e-01  1.36288028e+00]\n",
            " [-5.69953976e-01 -2.33674344e+00  9.45137269e-01  2.71880106e-01]\n",
            " [ 3.97410146e-01 -3.84002368e-02  5.23701488e-01 -1.41231987e+00]\n",
            " [-1.27587211e+00 -1.43563201e+00 -2.20371580e+00  4.25898913e-01]\n",
            " [-2.83565696e-01 -1.64199251e+00  1.58401672e+00  1.19329414e+00]\n",
            " [-7.42659423e-02 -6.19991523e-01  9.79964534e-01  9.57246067e-01]\n",
            " [ 1.97516664e-01  4.08932310e-01 -5.22331131e-01 -1.26078119e+00]\n",
            " [ 5.03449415e-01  1.19288667e+00 -4.84935682e-01 -1.36690852e+00]\n",
            " [-9.31465029e-01 -1.16588145e+00 -1.13925443e+00  9.27811613e-01]\n",
            " [ 1.39122946e+00  2.19179136e+00  2.69003753e+00  1.32686448e+00]\n",
            " [-7.00753539e-01 -1.70324965e+00 -6.34578394e-01 -5.69616584e-01]\n",
            " [-1.21326163e+00 -1.39181233e+00 -1.41272316e+00  1.59491271e+00]\n",
            " [-6.00185450e-01 -2.34545494e+00  1.05879625e+00  6.35363403e-01]\n",
            " [ 6.80504171e-02  6.94056876e-01 -2.05221417e+00 -2.72462039e+00]\n",
            " [ 1.59613050e-01 -9.01215104e-01  1.01934480e+00 -8.87292869e-01]\n",
            " [ 3.98224856e-02 -7.40068225e-01  3.19413623e-01 -1.14610947e+00]\n",
            " [ 3.56334396e-01  5.80345953e-01  1.04034525e+00  1.01824611e+00]\n",
            " [-6.75424155e-01  1.06645470e+00 -3.00376448e+00  5.77517599e-01]\n",
            " [-3.49564852e-01 -6.69270121e-01 -1.09902562e-01  4.57542064e-01]\n",
            " [ 8.73538018e-01  8.22027393e-01  2.32696269e+00  8.72929403e-01]\n",
            " [-1.38477543e-02  9.53986821e-01 -1.42957398e+00 -5.92491421e-01]\n",
            " [-9.33178010e-01 -9.32271665e-01 -2.81135109e+00 -1.63506433e+00]\n",
            " [-4.67118896e-01 -1.54116436e-03 -2.19782464e-01  2.28646177e+00]\n",
            " [ 2.41781160e-01  1.02675996e+00  3.30222373e-01  1.28836248e+00]]\n",
            "Labels: [2 1 0 2 0 1 0 2 1 2 1 2 0 2 0 1 0 2 2 1 2 0 1 1 0 1 2 1 2 0 0 2 2 0 0 2 1\n",
            " 2 1 0 1 2 1 2 2 2 1 1 2 0 1 1 2 2 0 2 0 1 1 2 1 1 1 1 2 0 1 0 0 0 2 0 2 0\n",
            " 2 2 2 1 2 2 0 1 1 1 2 0 2 2 2 2 0 0 0 1 2 0 1 2 2 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encoding of labels\n",
        "ohe = OneHotEncoder(sparse_output=False)\n",
        "y_one_hot = ohe.fit_transform(y.reshape(-1, 1))\n",
        "print(\"One-Hot Encoded Labels:\")\n",
        "print(y_one_hot[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ewt3CtJRpaLZ",
        "outputId": "a87c1fcd-b148-4abb-9fb4-db543eb51aa4"
      },
      "id": "Ewt3CtJRpaLZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-Hot Encoded Labels:\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into Training and Testing Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "5bhHwPPhp-ZC"
      },
      "id": "5bhHwPPhp-ZC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize Features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "print(\"Standardized Training Features:\")\n",
        "print(X_train[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAtv1V6hqByd",
        "outputId": "a1c26cb0-5b0a-4b55-e702-bf6a6dea6b44"
      },
      "id": "FAtv1V6hqByd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standardized Training Features:\n",
            "[[ 0.82824262 -0.49192863  1.07799796 -1.55605876]\n",
            " [-0.41415237 -0.79355707  1.10671746  1.66891098]\n",
            " [-0.0637306   0.45091386 -0.23397134  0.76381877]\n",
            " [-1.14583527 -1.04779579 -0.82053612 -0.46507469]\n",
            " [-1.65901934 -0.26184995 -1.28301812  2.00614525]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to PyTorch Tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "8kM8VIl9qEIF"
      },
      "id": "8kM8VIl9qEIF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define the Neural Network Architecture\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 3)\n",
        "        self.fc2 = nn.Linear(3, 4)\n",
        "        self.fc3 = nn.Linear(4, 3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.softmax(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "# Initialize the Model\n",
        "model = NeuralNetwork()\n",
        "print(\"Neural Network Model:\")\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5naTIOPjqIVM",
        "outputId": "8f0c6133-62bb-478a-a7b8-85b9295a08ac"
      },
      "id": "5naTIOPjqIVM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural Network Model:\n",
            "NeuralNetwork(\n",
            "  (fc1): Linear(in_features=4, out_features=3, bias=True)\n",
            "  (fc2): Linear(in_features=3, out_features=4, bias=True)\n",
            "  (fc3): Linear(in_features=4, out_features=3, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 8)\n",
        "        self.fc2 = nn.Linear(8, 6)\n",
        "        self.fc3 = nn.Linear(6, 3)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "model = MyModel()"
      ],
      "metadata": {
        "id": "v1toKdI3q6V0"
      },
      "id": "v1toKdI3q6V0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def do_adam(X, Y, init_w, init_b, eta=0.1, max_epochs=1000, beta1=0.9, beta2=0.999, eps=1e-8):\n",
        "    w = init_w\n",
        "    b = init_b\n",
        "\n",
        "    # Initialize moment estimates\n",
        "    m_w, m_b = 0, 0  # First moment (mean)\n",
        "    v_w, v_b = 0, 0  # Second moment (variance)\n",
        "\n",
        "    # Initialize history for tracking progress\n",
        "    w_history, b_history, error_history = [], [], []\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        dw, db = 0, 0  # Initialize gradients\n",
        "\n",
        "        for x, y in zip(X, Y):\n",
        "            dw_i = grad_w(w, b, x, y)  # Calculate gradient w.r.t. w\n",
        "            db_i = grad_b(w, b, x, y)  # Calculate gradient w.r.t. b\n",
        "\n",
        "            dw += dw_i\n",
        "            db += db_i\n",
        "\n",
        "        # Apply bias correction for first and second moments\n",
        "        m_w = beta1 * m_w + (1 - beta1) * dw\n",
        "        m_b = beta1 * m_b + (1 - beta1) * db\n",
        "\n",
        "        v_w = beta2 * v_w + (1 - beta2) * (dw ** 2)\n",
        "        v_b = beta2 * v_b + (1 - beta2) * (db ** 2)\n",
        "\n",
        "        m_w_hat = m_w / (1 - beta1 ** (epoch + 1))\n",
        "        m_b_hat = m_b / (1 - beta1 ** (epoch + 1))\n",
        "\n",
        "        v_w_hat = v_w / (1 - beta2 ** (epoch + 1))\n",
        "        v_b_hat = v_b / (1 - beta2 ** (epoch + 1))\n",
        "\n",
        "        # Update weights and biases\n",
        "        w -= eta * m_w_hat / (np.sqrt(v_w_hat) + eps)\n",
        "        b -= eta * m_b_hat / (np.sqrt(v_b_hat) + eps)\n",
        "\n",
        "        # Track progress\n",
        "        w_history.append(w)\n",
        "        b_history.append(b)\n",
        "        error_history.append(compute_loss(w, b, X, Y))\n",
        "\n",
        "        # Print progress (every 100 epochs for example)\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{max_epochs}], Loss: {error_history[-1]:.4f}\")\n",
        "\n",
        "    return w, b, w_history, b_history, error_history"
      ],
      "metadata": {
        "id": "Lamk3Oc0Puuk"
      },
      "id": "Lamk3Oc0Puuk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_stochastic_gradient_descent(X, Y, init_w, init_b, eta=1.0, max_epochs=1000):\n",
        "    w = init_w\n",
        "    b = init_b\n",
        "\n",
        "    # Initialize history for tracking progress\n",
        "    w_history, b_history, error_history = [], [], []\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        dw, db = 0, 0  # Initialize gradients\n",
        "\n",
        "        for x, y in zip(X, Y):\n",
        "            dw_i = grad_w(w, b, x, y)  # Calculate gradient w.r.t. w\n",
        "            db_i = grad_b(w, b, x, y)  # Calculate gradient w.r.t. b\n",
        "\n",
        "            dw += dw_i\n",
        "            db += db_i\n",
        "\n",
        "        # Update weights and biases\n",
        "        w -= eta * dw\n",
        "        b -= eta * db\n",
        "\n",
        "        # Track progress\n",
        "        w_history.append(w)\n",
        "        b_history.append(b)\n",
        "        error_history.append(compute_loss(w, b, X, Y))\n",
        "\n",
        "        # Print progress (every 100 epochs for example)\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{max_epochs}], Loss: {error_history[-1]:.4f}\")\n",
        "\n",
        "    return w, b, w_history, b_history, error_history\n"
      ],
      "metadata": {
        "id": "W4_sCNmUPxec"
      },
      "id": "W4_sCNmUPxec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Gradient Functions\n",
        "def grad_w(w, b, x, y):\n",
        "    # Calculate gradient of w (example for linear regression)\n",
        "    return (2 * (w * x + b - y) * x)\n",
        "\n",
        "def grad_b(w, b, x, y):\n",
        "    # Calculate gradient of b (example for linear regression)\n",
        "    return 2 * (w * x + b - y)\n",
        "# Example Loss Function\n",
        "def compute_loss(w, b, X, Y):\n",
        "    # Calculate Mean Squared Error (MSE) loss\n",
        "    loss = 0\n",
        "    for x, y in zip(X, Y):\n",
        "        loss += (w * x + b - y) ** 2\n",
        "    return loss.item() / len(X)  # Return a scalar value using .item()"
      ],
      "metadata": {
        "id": "UwEbpn6RP1Oc"
      },
      "id": "UwEbpn6RP1Oc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize your parameters (e.g., for a linear model)\n",
        "init_w, init_b = 0.0, 0.0\n",
        "eta = 0.1  # Learning rate\n",
        "max_epochs = 1000  # Number of epochs\n",
        "\n",
        "# Define your dataset (X and Y)\n",
        "X = np.random.randn(100, 1)  # 100 data points, 1 feature\n",
        "Y = 2 * X + 1 + np.random.randn(100, 1)  # Linear relation with noise\n",
        "\n",
        "# Train with Adam\n",
        "print(\"Training with Adam:\")\n",
        "w_adam, b_adam, w_history_adam, b_history_adam, error_history_adam = do_adam(X, Y, init_w, init_b, eta)\n",
        "\n",
        "# Train with SGD\n",
        "print(\"\\nTraining with SGD:\")\n",
        "w_sgd, b_sgd, w_history_sgd, b_history_sgd, error_history_sgd = do_stochastic_gradient_descent(X, Y, init_w, init_b, eta)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKRloFctP4Yz",
        "outputId": "55f1fcef-a247-480b-9d39-d6496d727049"
      },
      "id": "rKRloFctP4Yz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with Adam:\n",
            "Epoch [1/1000], Loss: 6.4577\n",
            "Epoch [101/1000], Loss: 1.1130\n",
            "Epoch [201/1000], Loss: 1.1129\n",
            "Epoch [301/1000], Loss: 1.1129\n",
            "Epoch [401/1000], Loss: 1.1129\n",
            "Epoch [501/1000], Loss: 1.1129\n",
            "Epoch [601/1000], Loss: 1.1129\n",
            "Epoch [701/1000], Loss: 1.1129\n",
            "Epoch [801/1000], Loss: 1.1129\n",
            "Epoch [901/1000], Loss: 1.1129\n",
            "\n",
            "Training with SGD:\n",
            "Epoch [1/1000], Loss: 2883.5692\n",
            "Epoch [101/1000], Loss: 2510178465144244113340300210684942669579395679736910021573528789116357059295937257899920911675567082173163254437256490932426485239511590704837178253314683687536455959280117505003983726627160914490367494976834832017794096899307543809233055146005985582448743054878290292506624.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-8e8237a4ab97>:14: RuntimeWarning: overflow encountered in square\n",
            "  loss += (w * x + b - y) ** 2\n",
            "<ipython-input-47-9927bdd9f585>:15: RuntimeWarning: overflow encountered in add\n",
            "  dw += dw_i\n",
            "<ipython-input-47-9927bdd9f585>:16: RuntimeWarning: overflow encountered in add\n",
            "  db += db_i\n",
            "<ipython-input-50-8e8237a4ab97>:14: RuntimeWarning: invalid value encountered in add\n",
            "  loss += (w * x + b - y) ** 2\n",
            "<ipython-input-50-8e8237a4ab97>:4: RuntimeWarning: invalid value encountered in add\n",
            "  return (2 * (w * x + b - y) * x)\n",
            "<ipython-input-50-8e8237a4ab97>:8: RuntimeWarning: invalid value encountered in add\n",
            "  return 2 * (w * x + b - y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [201/1000], Loss: inf\n",
            "Epoch [301/1000], Loss: nan\n",
            "Epoch [401/1000], Loss: nan\n",
            "Epoch [501/1000], Loss: nan\n",
            "Epoch [601/1000], Loss: nan\n",
            "Epoch [701/1000], Loss: nan\n",
            "Epoch [801/1000], Loss: nan\n",
            "Epoch [901/1000], Loss: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and Optimizer (You can use either SGD or Adam)\n",
        "criterion = nn.CrossEntropyLoss()  # Use CrossEntropyLoss for multi-class classification\n",
        "optimizer_sgd = optim.SGD(model.parameters(), lr=0.01)\n",
        "optimizer_adam = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "def train_model(optimizer, epochs=100):\n",
        "    loss_history = []\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()  # Clear previous gradients\n",
        "        outputs = model(X_train_tensor)  # Forward pass\n",
        "        loss = criterion(outputs, y_train_tensor)  # Compute loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update weights\n",
        "        loss_history.append(loss.item())\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "    return loss_history"
      ],
      "metadata": {
        "id": "k2J2S9NNOnhs"
      },
      "id": "k2J2S9NNOnhs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Keras model\n",
        "model1 = models.Sequential()\n",
        "model1.add(layers.InputLayer(input_shape=(4,), name=\"Input Layer\"))\n",
        "model1.add(layers.Dense(8, activation='relu', name=\"Hidden1\"))\n",
        "model1.add(layers.Dense(6, activation='relu', name=\"Hidden2\"))\n",
        "model1.add(layers.Dense(3, activation='softmax', name=\"OutputLayer\"))\n",
        "\n",
        "# Compile the model\n",
        "model1.compile(optimizer='sgd',\n",
        "               loss='sparse_categorical_crossentropy',  # For integer labels\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "# Assuming X and y are your input and output data\n",
        "# Train the Keras model\n",
        "model1.fit(X, y, epochs=100, batch_size=64, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tBmUqhU8X8U",
        "outputId": "a837aacc-5d72-4482-b568-65ec5327e53e"
      },
      "id": "1tBmUqhU8X8U",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 232ms/step - accuracy: 0.4087 - loss: 1.1360 - val_accuracy: 0.3000 - val_loss: 1.1514\n",
            "Epoch 2/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4325 - loss: 1.1142 - val_accuracy: 0.3000 - val_loss: 1.1499\n",
            "Epoch 3/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.4273 - loss: 1.1251 - val_accuracy: 0.3000 - val_loss: 1.1484\n",
            "Epoch 4/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4429 - loss: 1.1239 - val_accuracy: 0.3000 - val_loss: 1.1473\n",
            "Epoch 5/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4481 - loss: 1.1180 - val_accuracy: 0.3000 - val_loss: 1.1460\n",
            "Epoch 6/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.4117 - loss: 1.1257 - val_accuracy: 0.3000 - val_loss: 1.1451\n",
            "Epoch 7/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4065 - loss: 1.1350 - val_accuracy: 0.3000 - val_loss: 1.1444\n",
            "Epoch 8/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4169 - loss: 1.1174 - val_accuracy: 0.3000 - val_loss: 1.1433\n",
            "Epoch 9/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4117 - loss: 1.1252 - val_accuracy: 0.3000 - val_loss: 1.1426\n",
            "Epoch 10/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.4377 - loss: 1.0993 - val_accuracy: 0.3000 - val_loss: 1.1414\n",
            "Epoch 11/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.4087 - loss: 1.1366 - val_accuracy: 0.3000 - val_loss: 1.1411\n",
            "Epoch 12/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4347 - loss: 1.1174 - val_accuracy: 0.3000 - val_loss: 1.1405\n",
            "Epoch 13/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4295 - loss: 1.1245 - val_accuracy: 0.3000 - val_loss: 1.1399\n",
            "Epoch 14/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.4399 - loss: 1.1131 - val_accuracy: 0.3000 - val_loss: 1.1390\n",
            "Epoch 15/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4451 - loss: 1.1004 - val_accuracy: 0.3000 - val_loss: 1.1381\n",
            "Epoch 16/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4295 - loss: 1.0959 - val_accuracy: 0.3000 - val_loss: 1.1369\n",
            "Epoch 17/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.4399 - loss: 1.0929 - val_accuracy: 0.3000 - val_loss: 1.1358\n",
            "Epoch 18/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.4525 - loss: 1.1030 - val_accuracy: 0.3000 - val_loss: 1.1351\n",
            "Epoch 19/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.4652 - loss: 1.1080 - val_accuracy: 0.3000 - val_loss: 1.1344\n",
            "Epoch 20/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4391 - loss: 1.1120 - val_accuracy: 0.3000 - val_loss: 1.1337\n",
            "Epoch 21/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4756 - loss: 1.1012 - val_accuracy: 0.3000 - val_loss: 1.1329\n",
            "Epoch 22/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.4391 - loss: 1.1164 - val_accuracy: 0.3000 - val_loss: 1.1327\n",
            "Epoch 23/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.4391 - loss: 1.1085 - val_accuracy: 0.3000 - val_loss: 1.1324\n",
            "Epoch 24/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4600 - loss: 1.1044 - val_accuracy: 0.3000 - val_loss: 1.1320\n",
            "Epoch 25/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4317 - loss: 1.1034 - val_accuracy: 0.3000 - val_loss: 1.1316\n",
            "Epoch 26/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4317 - loss: 1.1046 - val_accuracy: 0.3000 - val_loss: 1.1308\n",
            "Epoch 27/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.4525 - loss: 1.1036 - val_accuracy: 0.3000 - val_loss: 1.1303\n",
            "Epoch 28/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.4503 - loss: 1.0922 - val_accuracy: 0.3000 - val_loss: 1.1296\n",
            "Epoch 29/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4481 - loss: 1.0913 - val_accuracy: 0.3000 - val_loss: 1.1289\n",
            "Epoch 30/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4169 - loss: 1.1070 - val_accuracy: 0.3000 - val_loss: 1.1287\n",
            "Epoch 31/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4221 - loss: 1.0999 - val_accuracy: 0.3000 - val_loss: 1.1283\n",
            "Epoch 32/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4221 - loss: 1.0948 - val_accuracy: 0.3000 - val_loss: 1.1279\n",
            "Epoch 33/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4451 - loss: 1.0990 - val_accuracy: 0.3000 - val_loss: 1.1275\n",
            "Epoch 34/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.4556 - loss: 1.0845 - val_accuracy: 0.3000 - val_loss: 1.1269\n",
            "Epoch 35/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.4191 - loss: 1.1072 - val_accuracy: 0.3000 - val_loss: 1.1267\n",
            "Epoch 36/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.4243 - loss: 1.1027 - val_accuracy: 0.3000 - val_loss: 1.1267\n",
            "Epoch 37/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.4243 - loss: 1.0964 - val_accuracy: 0.3000 - val_loss: 1.1263\n",
            "Epoch 38/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.4503 - loss: 1.0862 - val_accuracy: 0.3000 - val_loss: 1.1257\n",
            "Epoch 39/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.4169 - loss: 1.0899 - val_accuracy: 0.3000 - val_loss: 1.1255\n",
            "Epoch 40/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.4377 - loss: 1.0807 - val_accuracy: 0.3000 - val_loss: 1.1248\n",
            "Epoch 41/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.4325 - loss: 1.0847 - val_accuracy: 0.3000 - val_loss: 1.1246\n",
            "Epoch 42/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.4221 - loss: 1.0854 - val_accuracy: 0.3000 - val_loss: 1.1242\n",
            "Epoch 43/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.4273 - loss: 1.0862 - val_accuracy: 0.3000 - val_loss: 1.1236\n",
            "Epoch 44/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.4273 - loss: 1.0914 - val_accuracy: 0.3000 - val_loss: 1.1235\n",
            "Epoch 45/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.4065 - loss: 1.1004 - val_accuracy: 0.3000 - val_loss: 1.1233\n",
            "Epoch 46/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4065 - loss: 1.0933 - val_accuracy: 0.3000 - val_loss: 1.1230\n",
            "Epoch 47/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4117 - loss: 1.0931 - val_accuracy: 0.3000 - val_loss: 1.1227\n",
            "Epoch 48/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.4273 - loss: 1.0830 - val_accuracy: 0.3000 - val_loss: 1.1223\n",
            "Epoch 49/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4377 - loss: 1.0773 - val_accuracy: 0.3000 - val_loss: 1.1219\n",
            "Epoch 50/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.4295 - loss: 1.0876 - val_accuracy: 0.3000 - val_loss: 1.1216\n",
            "Epoch 51/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4243 - loss: 1.0942 - val_accuracy: 0.3000 - val_loss: 1.1216\n",
            "Epoch 52/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4295 - loss: 1.0959 - val_accuracy: 0.3000 - val_loss: 1.1217\n",
            "Epoch 53/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.4347 - loss: 1.0803 - val_accuracy: 0.3000 - val_loss: 1.1213\n",
            "Epoch 54/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4295 - loss: 1.0868 - val_accuracy: 0.3000 - val_loss: 1.1213\n",
            "Epoch 55/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4295 - loss: 1.0937 - val_accuracy: 0.3000 - val_loss: 1.1210\n",
            "Epoch 56/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4399 - loss: 1.0778 - val_accuracy: 0.3000 - val_loss: 1.1208\n",
            "Epoch 57/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.4503 - loss: 1.0803 - val_accuracy: 0.3000 - val_loss: 1.1207\n",
            "Epoch 58/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4503 - loss: 1.0771 - val_accuracy: 0.3000 - val_loss: 1.1202\n",
            "Epoch 59/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4503 - loss: 1.0756 - val_accuracy: 0.3000 - val_loss: 1.1197\n",
            "Epoch 60/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4295 - loss: 1.0893 - val_accuracy: 0.3000 - val_loss: 1.1197\n",
            "Epoch 61/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.4503 - loss: 1.0731 - val_accuracy: 0.3000 - val_loss: 1.1192\n",
            "Epoch 62/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.4347 - loss: 1.0803 - val_accuracy: 0.2000 - val_loss: 1.1190\n",
            "Epoch 63/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.4191 - loss: 1.0896 - val_accuracy: 0.2000 - val_loss: 1.1190\n",
            "Epoch 64/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.4243 - loss: 1.0925 - val_accuracy: 0.2000 - val_loss: 1.1191\n",
            "Epoch 65/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.4399 - loss: 1.0778 - val_accuracy: 0.2000 - val_loss: 1.1186\n",
            "Epoch 66/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.4243 - loss: 1.0889 - val_accuracy: 0.2000 - val_loss: 1.1185\n",
            "Epoch 67/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.4243 - loss: 1.0786 - val_accuracy: 0.2000 - val_loss: 1.1182\n",
            "Epoch 68/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4013 - loss: 1.0905 - val_accuracy: 0.2000 - val_loss: 1.1183\n",
            "Epoch 69/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.4221 - loss: 1.0821 - val_accuracy: 0.2000 - val_loss: 1.1183\n",
            "Epoch 70/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4421 - loss: 1.0828 - val_accuracy: 0.2000 - val_loss: 1.1182\n",
            "Epoch 71/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4578 - loss: 1.0885 - val_accuracy: 0.2000 - val_loss: 1.1181\n",
            "Epoch 72/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4421 - loss: 1.0839 - val_accuracy: 0.2000 - val_loss: 1.1179\n",
            "Epoch 73/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.4317 - loss: 1.0835 - val_accuracy: 0.2000 - val_loss: 1.1179\n",
            "Epoch 74/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4421 - loss: 1.0856 - val_accuracy: 0.2000 - val_loss: 1.1178\n",
            "Epoch 75/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.4265 - loss: 1.0868 - val_accuracy: 0.2000 - val_loss: 1.1176\n",
            "Epoch 76/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.4525 - loss: 1.0712 - val_accuracy: 0.2000 - val_loss: 1.1173\n",
            "Epoch 77/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4421 - loss: 1.0846 - val_accuracy: 0.2000 - val_loss: 1.1173\n",
            "Epoch 78/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.4682 - loss: 1.0716 - val_accuracy: 0.2000 - val_loss: 1.1170\n",
            "Epoch 79/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4503 - loss: 1.0673 - val_accuracy: 0.2000 - val_loss: 1.1167\n",
            "Epoch 80/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4399 - loss: 1.0751 - val_accuracy: 0.2000 - val_loss: 1.1164\n",
            "Epoch 81/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4399 - loss: 1.0744 - val_accuracy: 0.2000 - val_loss: 1.1163\n",
            "Epoch 82/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4295 - loss: 1.0747 - val_accuracy: 0.2000 - val_loss: 1.1163\n",
            "Epoch 83/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4295 - loss: 1.0774 - val_accuracy: 0.2000 - val_loss: 1.1160\n",
            "Epoch 84/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.4399 - loss: 1.0768 - val_accuracy: 0.2000 - val_loss: 1.1159\n",
            "Epoch 85/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.4087 - loss: 1.0873 - val_accuracy: 0.2000 - val_loss: 1.1159\n",
            "Epoch 86/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4451 - loss: 1.0715 - val_accuracy: 0.2000 - val_loss: 1.1157\n",
            "Epoch 87/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4503 - loss: 1.0615 - val_accuracy: 0.2000 - val_loss: 1.1153\n",
            "Epoch 88/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4369 - loss: 1.0715 - val_accuracy: 0.2000 - val_loss: 1.1152\n",
            "Epoch 89/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4369 - loss: 1.0776 - val_accuracy: 0.2000 - val_loss: 1.1151\n",
            "Epoch 90/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.4317 - loss: 1.0689 - val_accuracy: 0.2000 - val_loss: 1.1148\n",
            "Epoch 91/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4525 - loss: 1.0719 - val_accuracy: 0.2000 - val_loss: 1.1148\n",
            "Epoch 92/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4317 - loss: 1.0821 - val_accuracy: 0.2000 - val_loss: 1.1147\n",
            "Epoch 93/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4525 - loss: 1.0677 - val_accuracy: 0.2000 - val_loss: 1.1144\n",
            "Epoch 94/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.4421 - loss: 1.0758 - val_accuracy: 0.2000 - val_loss: 1.1142\n",
            "Epoch 95/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.4317 - loss: 1.0774 - val_accuracy: 0.2000 - val_loss: 1.1143\n",
            "Epoch 96/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4347 - loss: 1.0721 - val_accuracy: 0.2000 - val_loss: 1.1141\n",
            "Epoch 97/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4608 - loss: 1.0633 - val_accuracy: 0.2000 - val_loss: 1.1138\n",
            "Epoch 98/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.4347 - loss: 1.0710 - val_accuracy: 0.2000 - val_loss: 1.1136\n",
            "Epoch 99/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4295 - loss: 1.0692 - val_accuracy: 0.2000 - val_loss: 1.1135\n",
            "Epoch 100/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4243 - loss: 1.0792 - val_accuracy: 0.2000 - val_loss: 1.1135\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c287fe0b690>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train with Adam Optimizer\n",
        "print(\"\\nTraining with Adam Optimizer:\")\n",
        "adam_loss_history = train_model(optimizer_adam)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95igaH9W6GJ8",
        "outputId": "f6c65b4c-9b02-4d66-daae-6e35725c8e05"
      },
      "id": "95igaH9W6GJ8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with Adam Optimizer:\n",
            "Epoch [1/100], Loss: 1.0981\n",
            "Epoch [2/100], Loss: 1.0953\n",
            "Epoch [3/100], Loss: 1.0925\n",
            "Epoch [4/100], Loss: 1.0896\n",
            "Epoch [5/100], Loss: 1.0867\n",
            "Epoch [6/100], Loss: 1.0837\n",
            "Epoch [7/100], Loss: 1.0806\n",
            "Epoch [8/100], Loss: 1.0774\n",
            "Epoch [9/100], Loss: 1.0741\n",
            "Epoch [10/100], Loss: 1.0706\n",
            "Epoch [11/100], Loss: 1.0670\n",
            "Epoch [12/100], Loss: 1.0633\n",
            "Epoch [13/100], Loss: 1.0594\n",
            "Epoch [14/100], Loss: 1.0552\n",
            "Epoch [15/100], Loss: 1.0508\n",
            "Epoch [16/100], Loss: 1.0460\n",
            "Epoch [17/100], Loss: 1.0410\n",
            "Epoch [18/100], Loss: 1.0358\n",
            "Epoch [19/100], Loss: 1.0305\n",
            "Epoch [20/100], Loss: 1.0250\n",
            "Epoch [21/100], Loss: 1.0194\n",
            "Epoch [22/100], Loss: 1.0136\n",
            "Epoch [23/100], Loss: 1.0077\n",
            "Epoch [24/100], Loss: 1.0016\n",
            "Epoch [25/100], Loss: 0.9952\n",
            "Epoch [26/100], Loss: 0.9886\n",
            "Epoch [27/100], Loss: 0.9817\n",
            "Epoch [28/100], Loss: 0.9744\n",
            "Epoch [29/100], Loss: 0.9668\n",
            "Epoch [30/100], Loss: 0.9588\n",
            "Epoch [31/100], Loss: 0.9506\n",
            "Epoch [32/100], Loss: 0.9424\n",
            "Epoch [33/100], Loss: 0.9341\n",
            "Epoch [34/100], Loss: 0.9259\n",
            "Epoch [35/100], Loss: 0.9178\n",
            "Epoch [36/100], Loss: 0.9097\n",
            "Epoch [37/100], Loss: 0.9014\n",
            "Epoch [38/100], Loss: 0.8929\n",
            "Epoch [39/100], Loss: 0.8843\n",
            "Epoch [40/100], Loss: 0.8755\n",
            "Epoch [41/100], Loss: 0.8668\n",
            "Epoch [42/100], Loss: 0.8582\n",
            "Epoch [43/100], Loss: 0.8498\n",
            "Epoch [44/100], Loss: 0.8418\n",
            "Epoch [45/100], Loss: 0.8343\n",
            "Epoch [46/100], Loss: 0.8271\n",
            "Epoch [47/100], Loss: 0.8204\n",
            "Epoch [48/100], Loss: 0.8142\n",
            "Epoch [49/100], Loss: 0.8084\n",
            "Epoch [50/100], Loss: 0.8030\n",
            "Epoch [51/100], Loss: 0.7979\n",
            "Epoch [52/100], Loss: 0.7931\n",
            "Epoch [53/100], Loss: 0.7885\n",
            "Epoch [54/100], Loss: 0.7841\n",
            "Epoch [55/100], Loss: 0.7798\n",
            "Epoch [56/100], Loss: 0.7757\n",
            "Epoch [57/100], Loss: 0.7717\n",
            "Epoch [58/100], Loss: 0.7680\n",
            "Epoch [59/100], Loss: 0.7645\n",
            "Epoch [60/100], Loss: 0.7613\n",
            "Epoch [61/100], Loss: 0.7584\n",
            "Epoch [62/100], Loss: 0.7556\n",
            "Epoch [63/100], Loss: 0.7531\n",
            "Epoch [64/100], Loss: 0.7508\n",
            "Epoch [65/100], Loss: 0.7487\n",
            "Epoch [66/100], Loss: 0.7468\n",
            "Epoch [67/100], Loss: 0.7449\n",
            "Epoch [68/100], Loss: 0.7431\n",
            "Epoch [69/100], Loss: 0.7413\n",
            "Epoch [70/100], Loss: 0.7396\n",
            "Epoch [71/100], Loss: 0.7380\n",
            "Epoch [72/100], Loss: 0.7364\n",
            "Epoch [73/100], Loss: 0.7348\n",
            "Epoch [74/100], Loss: 0.7333\n",
            "Epoch [75/100], Loss: 0.7319\n",
            "Epoch [76/100], Loss: 0.7305\n",
            "Epoch [77/100], Loss: 0.7293\n",
            "Epoch [78/100], Loss: 0.7281\n",
            "Epoch [79/100], Loss: 0.7269\n",
            "Epoch [80/100], Loss: 0.7257\n",
            "Epoch [81/100], Loss: 0.7246\n",
            "Epoch [82/100], Loss: 0.7234\n",
            "Epoch [83/100], Loss: 0.7222\n",
            "Epoch [84/100], Loss: 0.7211\n",
            "Epoch [85/100], Loss: 0.7200\n",
            "Epoch [86/100], Loss: 0.7190\n",
            "Epoch [87/100], Loss: 0.7180\n",
            "Epoch [88/100], Loss: 0.7171\n",
            "Epoch [89/100], Loss: 0.7162\n",
            "Epoch [90/100], Loss: 0.7154\n",
            "Epoch [91/100], Loss: 0.7146\n",
            "Epoch [92/100], Loss: 0.7138\n",
            "Epoch [93/100], Loss: 0.7130\n",
            "Epoch [94/100], Loss: 0.7123\n",
            "Epoch [95/100], Loss: 0.7117\n",
            "Epoch [96/100], Loss: 0.7110\n",
            "Epoch [97/100], Loss: 0.7104\n",
            "Epoch [98/100], Loss: 0.7098\n",
            "Epoch [99/100], Loss: 0.7092\n",
            "Epoch [100/100], Loss: 0.7085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Evaluate Model Performance\n",
        "def evaluate_model():\n",
        "    with torch.no_grad():\n",
        "        predictions = model(X_test_tensor)\n",
        "        predicted_classes = torch.argmax(predictions, dim=1)\n",
        "        actual_classes = torch.argmax(y_test_tensor, dim=1)\n",
        "        accuracy = accuracy_score(actual_classes.numpy(), predicted_classes.numpy())\n",
        "        print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "print(\"\\nEvaluating Model Performance:\")\n",
        "evaluate_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sdKzSqIrBnd",
        "outputId": "ee11e900-9c50-4a3c-e595-2f36ac40f9ba"
      },
      "id": "8sdKzSqIrBnd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating Model Performance:\n",
            "Accuracy: 0.7250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(100), sgd_loss_history, label='SGD Loss')\n",
        "plt.plot(range(100), adam_loss_history, label='Adam Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Curve for SGD and Adam Optimizers')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "z15hCSKvrGh4",
        "outputId": "f4676880-9ef9-4c79-de5d-eb15ac0817b9"
      },
      "id": "z15hCSKvrGh4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RWGeLM0Drtz_"
      },
      "id": "RWGeLM0Drtz_",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}